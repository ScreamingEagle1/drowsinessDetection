{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drowsiness Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from pygame import mixer\n",
    "from keras.models import load_model\n",
    "\n",
    "from tkinter import *\n",
    "import tkinter.messagebox\n",
    "root=Tk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.geometry('500x500')\n",
    "frame = Frame(root, relief=RIDGE, borderwidth=2)\n",
    "frame.pack(fill=BOTH,expand=1)\n",
    "root.title('Driver Cam')\n",
    "frame.config(background='light blue')\n",
    "label = Label(frame, text=\"Driver Cam\",bg='light blue',font=('Times 35 bold'))\n",
    "label.pack(side=TOP)\n",
    "\n",
    "filename = PhotoImage(file=\"demo.png\")\n",
    "background_label = Label(frame,image=filename)\n",
    "background_label.pack(side=TOP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hel():\n",
    "   help(cv2)\n",
    "\n",
    "def Contri():\n",
    "   tkinter.messagebox.showinfo(\"Contributors\",\"\\n1.Sachin Kumar \\n2. Arpit \\n3. Rohit \\n\")\n",
    "\n",
    "def anotherWin():\n",
    "   tkinter.messagebox.showinfo(\"About\",'Driver Cam version v1.0\\n Made Using\\n-OpenCV\\n-Numpy\\n-Tkinter\\n In Python 3')\n",
    "                                    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MENU BAR\n",
    "menu = Menu(root)\n",
    "root.config(menu=menu)\n",
    "\n",
    "subm1 = Menu(menu)\n",
    "menu.add_cascade(label=\"Tools\",menu=subm1)\n",
    "subm1.add_command(label=\"Open CV Docs\",command=hel)\n",
    "\n",
    "subm2 = Menu(menu)\n",
    "menu.add_cascade(label=\"About\",menu=subm2)\n",
    "subm2.add_command(label=\"Driver Cam\",command=anotherWin)\n",
    "subm2.add_command(label=\"Contributors\",command=Contri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "sound = mixer.Sound('alarm.wav')\n",
    "\n",
    "face = cv2.CascadeClassifier('haar cascade files\\haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier('haar cascade files\\haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier('haar cascade files\\haarcascade_righteye_2splits.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0531 13:49:25.757809 11536 deprecation_wrapper.py:119] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0531 13:49:25.775045 11536 deprecation_wrapper.py:119] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0531 13:49:25.778778 11536 deprecation_wrapper.py:119] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0531 13:49:25.804110 11536 deprecation_wrapper.py:119] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0531 13:49:25.852700 11536 deprecation_wrapper.py:119] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0531 13:49:25.864792 11536 deprecation.py:506] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0531 13:49:25.987037 11536 deprecation_wrapper.py:119] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0531 13:49:26.139899 11536 deprecation_wrapper.py:119] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0531 13:49:26.245790 11536 deprecation.py:323] From C:\\Users\\ROHIT\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "lbl=['Close','Open']\n",
    "\n",
    "model = load_model('models/cnncat2.h5')\n",
    "path = os.getcwd()\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "count=0\n",
    "score=0\n",
    "thicc=2\n",
    "rpred=[99]\n",
    "lpred=[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitt():\n",
    "   exit()\n",
    " \n",
    "def web():\n",
    "   capture =cv2.VideoCapture(0)\n",
    "   while True:\n",
    "      ret,frame=capture.read()\n",
    "      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "      cv2.imshow('frame',frame)\n",
    "      if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "         break\n",
    "   capture.release()\n",
    "   cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataRecord():\n",
    "    import cv2\n",
    "    # Method to generate dataset to recognize a person\n",
    "    def generate_dataset(img, id, img_id,state):\n",
    "        # write image in data dir\n",
    "        cv2.imwrite(\"dataset/\"+str(state)+\"/\"+str(id)+\".\"+str(img_id)+\".jpg\", img)\n",
    "    state=input('enter state of eye: ')\n",
    "\n",
    "    # Method to draw boundary around the detected feature\n",
    "    def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text):\n",
    "        # Converting image to gray-scale\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # detecting features in gray-scale image, returns coordinates, width and height of features\n",
    "        features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "        coords = []\n",
    "        # drawing rectangle around the feature and labeling it\n",
    "        for (x, y, w, h) in features:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, text, (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "            coords = [x, y, w, h]\n",
    "        return coords\n",
    "\n",
    "\n",
    "    # Method to detect the features\n",
    "    def detect(img, faceCascade, img_id):\n",
    "        color = {\"blue\":(255,0,0), \"red\":(0,0,0), \"green\":(0,255,0), \"white\":(255,255,255)}\n",
    "        coords = draw_boundary(img, faceCascade, 1.1, 10, color['blue'], \"Face\")\n",
    "\n",
    "        cords2=draw_boundary(img, Leye_cascade, 1.1, 10, color['red'],'Leye')\n",
    "\n",
    "        cords3=draw_boundary(img, Reye_cascade, 1.1, 10, color['red'],'Reye')\n",
    "        # If feature is detected, the draw_boundary method will return the x,y coordinates and width and height of rectangle else the length of coords will be 0\n",
    "        if len(cords2)==4:\n",
    "    #         print('found')\n",
    "            # Updating region of interest by cropping image\n",
    "            roi_img = img[cords2[1]:cords2[1]+cords2[3], cords2[0]:cords2[0]+cords2[2]]\n",
    "            # Assign unique id to each user\n",
    "            user_id = 'left'\n",
    "            # img_id to make the name of each image unique\n",
    "            generate_dataset(roi_img, user_id, img_id,state)\n",
    "        if len(cords3)==4:\n",
    "    #         print('found')\n",
    "            # Updating region of interest by cropping image\n",
    "            roi_img = img[cords3[1]:cords3[1]+cords3[3], cords3[0]:cords3[0]+cords3[2]]\n",
    "            # Assign unique id to each user\n",
    "            user_id = 'right'\n",
    "            # img_id to make the name of each image unique\n",
    "            generate_dataset(roi_img, user_id, img_id,state)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "    # Loading classifiers\n",
    "    faceCascade = cv2.CascadeClassifier('haar cascade files\\haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    Leye_cascade=cv2.CascadeClassifier('haar cascade files\\haarcascade_lefteye_2splits.xml')\n",
    "\n",
    "    Reye_cascade=cv2.CascadeClassifier('haar cascade files\\haarcascade_righteye_2splits.xml')\n",
    "    # Capturing real time video stream. 0 for built-in web-cams, 0 or -1 for external web-cams\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Initialize img_id with 0\n",
    "    img_id = 0\n",
    "\n",
    "\n",
    "    while True:\n",
    "        if img_id % 50 == 0:\n",
    "            print(\"Collected \", img_id,\" images\")\n",
    "        # Reading image from video stream\n",
    "        _, img = video_capture.read()\n",
    "        # Call method we defined above\n",
    "        img = detect(img, faceCascade, img_id)\n",
    "        # Writing processed image in a new window\n",
    "        cv2.imshow(\"face detection\", img)\n",
    "        img_id += 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # releasing web-cam\n",
    "    video_capture.release()\n",
    "    # Destroying output window\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    import os\n",
    "    from keras.preprocessing import image\n",
    "    import matplotlib.pyplot as plt \n",
    "    import numpy as np\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    import random,shutil\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization\n",
    "    from keras.models import load_model\n",
    "\n",
    "\n",
    "    def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical' ):\n",
    "\n",
    "        return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size)\n",
    "\n",
    "    BS= 32\n",
    "    TS=(24,24)\n",
    "    train_batch= generator('data/train',shuffle=True, batch_size=BS,target_size=TS)\n",
    "    valid_batch= generator('data/valid',shuffle=True, batch_size=BS,target_size=TS)\n",
    "    SPE= len(train_batch.classes)//BS\n",
    "    VS = len(valid_batch.classes)//BS\n",
    "    print(\"length of train data \"+str(SPE))\n",
    "    print(\"lenth of test data \"+str(VS))\n",
    "    # print(SPE,VS)\n",
    "\n",
    "\n",
    "    img,labels= next(train_batch)\n",
    "    print(img.shape)\n",
    "    print(labels)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "        MaxPooling2D(pool_size=(1,1)),\n",
    "        Conv2D(32,(3,3),activation='relu'),\n",
    "        MaxPooling2D(pool_size=(1,1)),\n",
    "    #32 convolution filters used each of size 3x3\n",
    "    #again\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(1,1)),\n",
    "\n",
    "    #64 convolution filters used each of size 3x3\n",
    "    #choose the best features via pooling\n",
    "\n",
    "    #randomly turn neurons on and off to improve convergence\n",
    "        Dropout(0.25),\n",
    "    #flatten since too many dimensions, we only want a classification output\n",
    "        Flatten(),\n",
    "    #fully connected to get all relevant data\n",
    "        Dense(128, activation='relu'),\n",
    "    #one more dropout for convergence' sake :) \n",
    "        Dropout(0.5),\n",
    "    #output a softmax to squash the matrix into output probabilities\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)\n",
    "\n",
    "    model.save('model/cnnCat3.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webrec():\n",
    "   capture =cv2.VideoCapture(0)\n",
    "#    fourcc=cv2.VideoWriter_fourcc(*'XVID') \n",
    "#    op=cv2.VideoWriter('Sample1.avi',fourcc,11.0,(640,480))\n",
    "#    while True:\n",
    "#       ret,frame=capture.read()\n",
    "#       gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#       cv2.imshow('frame',frame)\n",
    "#       op.write(frame)\n",
    "#       if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "#       break\n",
    "#    op.release()\n",
    "   capture.release()\n",
    "   cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_drowsiness():\n",
    "    mixer.init()\n",
    "    sound = mixer.Sound('alarm.wav')\n",
    "\n",
    "    face = cv2.CascadeClassifier('haar cascade files\\haarcascade_frontalface_alt.xml')\n",
    "    leye = cv2.CascadeClassifier('haar cascade files\\haarcascade_lefteye_2splits.xml')\n",
    "    reye = cv2.CascadeClassifier('haar cascade files\\haarcascade_righteye_2splits.xml')\n",
    "\n",
    "\n",
    "\n",
    "    lbl=['Close','Open']\n",
    "\n",
    "    model = load_model('models/cnncat2.h5')\n",
    "    path = os.getcwd()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    count=0\n",
    "    score=0\n",
    "    thicc=2\n",
    "    rpred=[99]\n",
    "    lpred=[99]\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        height,width = frame.shape[:2] \n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "        left_eye = leye.detectMultiScale(gray)\n",
    "        right_eye =  reye.detectMultiScale(gray)\n",
    "\n",
    "        cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n",
    "            \n",
    "        for (ex,ey,ew,eh) in left_eye:\n",
    "            cv2.rectangle(frame,(ex,ey),(ex+ew,ey+eh),(100,55,0),2)\n",
    "            \n",
    "        for (ex,ey,ew,eh) in right_eye:\n",
    "            cv2.rectangle(frame,(ex,ey),(ex+ew,ey+eh),(100,55,0),2)\n",
    "    \n",
    "\n",
    "        for (x,y,w,h) in right_eye:\n",
    "            r_eye=frame[y:y+h,x:x+w]\n",
    "            count=count+1\n",
    "            r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "            r_eye = cv2.resize(r_eye,(24,24))\n",
    "            r_eye= r_eye/255\n",
    "            r_eye=  r_eye.reshape(24,24,-1)\n",
    "            r_eye = np.expand_dims(r_eye,axis=0)\n",
    "            rpred = model.predict_classes(r_eye)\n",
    "            if(rpred[0]==1):\n",
    "                lbl='Open' \n",
    "            if(rpred[0]==0):\n",
    "                lbl='Closed'\n",
    "            break\n",
    "\n",
    "        for (x,y,w,h) in left_eye:\n",
    "            l_eye=frame[y:y+h,x:x+w]\n",
    "            count=count+1\n",
    "            l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n",
    "            l_eye = cv2.resize(l_eye,(24,24))\n",
    "            l_eye= l_eye/255\n",
    "            l_eye=l_eye.reshape(24,24,-1)\n",
    "            l_eye = np.expand_dims(l_eye,axis=0)\n",
    "            lpred = model.predict_classes(l_eye)\n",
    "            if(lpred[0]==1):\n",
    "                lbl='Open'   \n",
    "            if(lpred[0]==0):\n",
    "                lbl='Closed'\n",
    "            break\n",
    "\n",
    "        if(rpred[0]==0 and lpred[0]==0):\n",
    "            score=score+1\n",
    "            cv2.putText(frame,\"Closed\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "        # if(rpred[0]==1 or lpred[0]==1):\n",
    "        else:\n",
    "            score=score-1\n",
    "            cv2.putText(frame,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        if(score<0):\n",
    "            score=0   \n",
    "        cv2.putText(frame,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "        if(score>15):\n",
    "            #person is feeling sleepy so we beep the alarm\n",
    "            cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "            try:\n",
    "                sound.play()\n",
    "\n",
    "            except:  # isplaying = False\n",
    "                pass\n",
    "            if(thicc<16):\n",
    "                thicc= thicc+2\n",
    "            else:\n",
    "                thicc=thicc-2\n",
    "                if(thicc<2):\n",
    "                    thicc=2\n",
    "            cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc) \n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "but1=Button(frame,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=web,text='Open Cam',font=('helvetica 15 bold'))\n",
    "but1.place(x=5,y=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but2=Button(frame,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=webrec,text='Open Cam & Record',font=('helvetica 15 bold'))\n",
    "# but2.place(x=5,y=176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "but3=Button(frame,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=dataRecord,text='Detect & Record Dataset',font=('helvetica 15 bold'))\n",
    "but3.place(x=5,y=176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "but4=Button(frame,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=trainModel,text='Train Model',font=('helvetica 15 bold'))\n",
    "but4.place(x=5,y=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "but5=Button(frame,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=detect_drowsiness,text='Detect Drowsiness and alert',font=('helvetica 15 bold'))\n",
    "but5.place(x=5,y=322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "but6=Button(frame,padx=5,pady=5,width=5,bg='white',fg='black',relief=GROOVE,text='EXIT',command=exitt,font=('helvetica 15 bold'))\n",
    "but6.place(x=210,y=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
